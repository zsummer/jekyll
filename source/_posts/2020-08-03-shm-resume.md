---
title: 共享内存RESUME综述 
date: 2020-08-03
categories: develop 
author: yawei.zhang 
mathjax: true
---

<!-- toc -->


## 前言    
**共享内存RESUME机制是指的: 通过将游戏状态数据保存在共享内存中, 当游戏进程crash后通过重启游戏服务器并attach已有的共享内存来恢复游戏状态, 以此达到玩家游戏体验在出现宕机时的连贯性, 提升游戏的容灾能力.**       


## 共享内存RESUME出现的情景   

### MMOACT相比传统互联网的异同        

在web领域中,  业务和数据分离, 从而达成'业务无状态化', 开发人员专注于业务本身, 状态数据的一致性问题和容灾问题转移到可以较为独立解决的数据存储领域, 这个领域有非常多的论文和解决方案, 以及成熟的服务等.     

而对于游戏领域来说, 互联网成熟的解决的方案很难在这个地方生效,  当然 对于外围系统来说, 我们仍然可以按照互联网成熟的解决方案进行布局, 例如聊天系统, 好友系统,  邮件系统, 日志系统,  或者一些游戏中的公会系统等.     


MMOACT的特性:  
* **CPU计算密集**   
  * 地图单位扫描选择 命中包围盒碰撞检测 战斗事件响应处理  AI的扫描检测,行为决策,  移动的寻路/碰撞避免/检测等    
  
* **IO密集**  
  * 视野内所有玩家的事件都要同步所有玩家(理想情况下), 这是一个$O(N^2)$的广播复杂度  
  * 大世界内视野范围较为开阔   
  
* **低延迟响应**   
  * 在战斗中, 一次攻击动作被拆解成逐帧开启和关闭的 霸体 无敌  攻击窗口 可闪避窗口 可打断窗口等流程片段, 一帧16.7ms  
  * 在战斗中每秒平均5~7米的移动距离, 100ms的延迟将会带来一个身位的偏差造成命中失败  
  * 弓箭的速度大约每秒50米, 30帧的客户端一帧就有两个身位的偏差  
  * 互联网骨干网20ms的延迟 每一点额外的延迟都会给同步带来较为巨大的压力.   
  
* **共享状态高频读写**   
  * 战斗单位与战斗单位之间, 战斗单位的模块与模块之间   
  * ACT战斗中实时响应判定的AI(大量事件和回调)  
  * 装备, 属性, 能量槽, 状态标签与技能和移动之间的相互引用与保证   
    * BUFF对属性的修改 标签的装载和卸载 子弹时间的进出等都需要严格保证对称   
  * 技能BUFF流程中跨战斗单位跨模块并需要严格保证时序的事件判定与脚本回执等   

* **重业务逻辑,需求易变**   
  * 业务类型繁多复杂且耦合, 见上栏'共享状态高频读写'   


传统互联网特性:  
* 数据规模大 用户量大 并发大  
* 轻业务, 重存储 对数据一致性要求较高    
  * 读写改查这几个基本操作可以涵盖绝大部分互联网业务的核心内容  
* 业务较为稳定  
* 延迟不敏感 通常都是秒级以上.  
  * google Analytics速度报告中, 网页的平均加载时间为8秒   2秒打开网页我们会觉得飞快(秒开)  
  * 互动式直播和视频会议的延迟平均1~3秒  
  * 苹果支付服务器验证一个支付凭据需要3s-6s   
  * 45秒才能看视频   

大部分互联网核心业务都能很好的进行业务和状态存储上的解耦, 用成熟的数据库相关的存储服务或者成熟的解决方案来订制解决, 其核心往往是通过牺牲响应速度, 提高解决方案的复杂度来实现大规模高一致性的互联网需求.   
(12306的业务也不算复杂 但是难在大规模并发下, 状态之间难以解耦进行传统的分而治之而造成的)

和游戏不同,  游戏往往本身就携带足够丰富复杂的各种业务系统相互耦合, 并且变更速度极为频繁且变更规模难以预测,  对响应时间有极高的要求,  往往是通过牺牲一定程度的低级别的状态可靠性和一致性(游戏实时状态)来达到游戏的流畅性,  以及牺牲一定程度的代码可靠性来达到较快的开发周期.    

在这种环境下,  互联网较为成熟的解决方案很难在游戏领域得到及时的应用,  带来的延迟问题难以容忍, 或者带来的复杂度在工程实践上难以以正常的进度期望完成,  问题域存在太多的差异.    


附图, MMO技能的基本流程如下:   
* 技能释放条件  --> 判断自身脚本 -->判断目标是否有脚本有则等待执行结果   
* 技能预处理   --> 判定  
* 技能释放成功  -->  判定  
* 技能命中开始扫描目标  --> 是否有反向过滤  --> 等待执行结果   
* 技能遍历所有选中目标
  * 即将对目标发起命中处理  --> 判定  
  * 对目标发起命中处理  
    * 遍历所有效果    
      * 即将对目标产生效果   --> 判定 
        * 如果是伤害则有 伤害预处理  -- >判定    
        * 如果是BUFF则有额外的buff流程判定  
      * 已经对目标产生效果  --> 判定  
        * 如果是伤害则有 伤害已经处理  -->判定  
    * 遍历所有效果完毕   
  * 已经对目标执行完命中处理  --> 判定   
* 技能遍历目标发起命中结束    
* 下一段命中  
* 技能即将结束  --> 判定  
* 技能已经结束   -->判定   

通常1V1战斗一次可能需要保证时序的同步点大约就有20个 而混战情况下则会有N倍的提升,  在非分布式的情况下, 所有的同步点带来的处理复杂度都是一次分支判定,  但是如果是分布式则会是一次rpc   .   
如果是共享内存下的消息队列实现  一次rpc来回则有10ms的延迟  

### 技术选型  
有成功案例的两种做法:   

一种不常见的BIGWORLD的做法(冗余系统&故障切换):   
* 以战斗单位进行解耦, 不同的战斗单位可以分布在不同节点   
* 游戏世界不按照场景地图划分, 而是按照战斗单位的负载动态切分   
* 所有单位进行跨物理节点的冗余, 故障后直接切换到备份单位继续战斗   
  
* 跨节点的战斗, 如果战斗系统同步点过多则不可避免的带来额外的延迟  
* RPC需求让系统变得更为复杂  开发和调试都会带来更多困难    
* 动态负载均衡难以实现  
* 需要面临的技术挑战过大且几乎没有多少有价值的参考资料和技术储备   


另外一种, 基于共享内存RESUME做法:   
* 状态数据持久化在共享内存中, 进程crash之后数据不丢失   
* 对使用者透明,  状态数据是在本地内存还是共享内存 对C/C++这种语言的使用者来说没有区别  
  * 经过完善的合理的包装设计, 可以做到业务人员对'共享内存'无感, 基本上做好状态和逻辑分离即可.   
* 对共享内存上的状态访问读写操作等同本地内存, 无额外性能消耗和处理延迟  
* RESUME后保持业务的连贯性, 对用户体验非常友好   
* 原理简单容易(分阶段)实现, 且每阶段都可验证,  有较多成功案例.   

### 架构拆分   

* 尽可能的拆分外围服务 以stateless集群+数据库存储方案来实现   
  * 例如好友 聊天 邮件等   

* 对无法做到stateless又难以拆分的管理节点和战斗节点进行RESUME设计.   



## 解决方案   


## 小的创新   


## 当前效果   







